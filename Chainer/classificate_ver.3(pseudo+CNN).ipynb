{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda\n",
    "import chainer.functions as F\n",
    "from chainer import optimizers\n",
    "import time\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpu_flag = 0\n",
    "\n",
    "if gpu_flag >= 0:\n",
    "    cuda.check_cuda_available()\n",
    "xp = cuda.cupy if gpu_flag >= 0 else np\n",
    "\n",
    "\n",
    "with open('/home/dl-box/Liver/sotsuron_train/train_pkl_data/new1024mix_NC_pseudocolor_classificate.pkl','rb') as f1:\n",
    "    dataset1 = pickle.load(f1)\n",
    "    \n",
    "with open('/data1/20171127/Test_dataset/Cyst/NC/Cyst106_NC_pseudo_classificate.pkl','rb') as f2:\n",
    "    dataset2 = pickle.load(f2)\n",
    "    \n",
    "train_set_x, train_set_y = dataset1[0]\n",
    "test_set_x, test_set_y = dataset2[0]\n",
    "\n",
    "train_set_x = np.array(train_set_x).astype(xp.float32)\n",
    "train_set_y = np.array(train_set_y).astype(xp.int32)\n",
    "test_set_x = np.array(test_set_x).astype(xp.float32)\n",
    "test_set_y = np.array(test_set_y).astype(xp.int32)\n",
    "\n",
    "x_train = train_set_x.reshape(train_set_x.shape[0],-1)\n",
    "y_train = train_set_y\n",
    "\n",
    "x_test = test_set_x.reshape(test_set_x.shape[0],-1)\n",
    "y_test = test_set_y\n",
    "\n",
    "N = x_train.shape[0]\n",
    "N_test = y_test.size\n",
    "\n",
    "x_train = x_train.reshape((len(x_train), 3, 29, 29))\n",
    "x_test = x_test.reshape((len(x_test), 3, 29, 29))\n",
    "x_train = (x_train*1.0)/255\n",
    "x_test = (x_test*1.0)/255\n",
    "\n",
    "class LeNet(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__(\n",
    "        conv1=F.Convolution2D(3, 96, 3),   \n",
    "        conv2=F.Convolution2D(96, 192, 3), \n",
    "        conv3=F.Convolution2D(192, 192, 2),\n",
    "        conv4=F.Convolution2D(192, 384, 2),\n",
    "        conv5=F.Convolution2D(384, 384, 2),\n",
    "        conv6=F.Convolution2D(384, 384, 2),\n",
    "        conv7=F.Convolution2D(384, 768, 2),\n",
    "        conv8=F.Convolution2D(768, 768, 2),\n",
    "        conv9=F.Convolution2D(768, 768, 2),\n",
    "        conv10=F.Convolution2D(768, 1536, 2),\n",
    "        conv11=F.Convolution2D(1536, 1536, 2),\n",
    "        conv12=F.Convolution2D(1536, 1536, 2),\n",
    "            l1=F.Linear(6144, 128),            \n",
    "            l2=F.Linear(128, 6)#classification\n",
    "        )\n",
    "        \n",
    "    def __call__(self,x_data,train = True):\n",
    "        #x = chainer.Variable(x_data)\n",
    "        x = chainer.Variable(x_data.astype(np.float32))\n",
    "        h = F.max_pooling_2d(F.relu(self.conv1(x)), 2)\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = F.relu(self.conv4(h))\n",
    "        h = F.relu(self.conv5(h))\n",
    "        h = F.relu(self.conv6(h))\n",
    "        h = F.relu(self.conv7(h))\n",
    "        h = F.relu(self.conv8(h))\n",
    "        h = F.relu(self.conv9(h))\n",
    "        h = F.relu(self.conv10(h))\n",
    "        h = F.relu(self.conv11(h))\n",
    "        h = F.relu(self.conv12(h))\n",
    "        h = F.dropout(F.relu(self.l1(h)), train= train)\n",
    "        y = self.l2(h)\n",
    "        y = F.relu(y)\n",
    "        return y\n",
    "\n",
    "    def forward_Train(self, x_data,y_data):\n",
    "        y = self(x_data ,True)\n",
    "        t = chainer.Variable(y_data)\n",
    "        return F.softmax_cross_entropy(y, t), F.accuracy(y,t)\n",
    "    \n",
    "    def forward_Test(self, x_data, y_data):\n",
    "        t = chainer.Variable(y_data)\n",
    "        y = self(x_data)\n",
    "        return F.accuracy(y, t)   \n",
    "        \n",
    "    def forward_label(self, x_data,y_data):\n",
    "        label_list = np.empty((0,6),int)\n",
    "        t = chainer.Variable(y_data)\n",
    "        y = self(x_data)\n",
    "        for i in range(0,y.data.shape[0]):\n",
    "            classificate_max = 0\n",
    "            classificate_max = max(y.data[i])\n",
    "            for j in range(0,6):\n",
    "                if classificate_max > y.data[i][j]:\n",
    "                    y.data[i][j] = 0\n",
    "                elif classificate_max == y.data[i][j]:\n",
    "                    y.data[i][j] = 1     \n",
    "                else:\n",
    "                    y.data[i][j] = 0\n",
    "            label_list = np.append(label_list, np.array([y.data[i]]), axis=0)\n",
    "        label_list2 = sum(label_list)\n",
    "        return label_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000\n",
      "240000\n",
      "28627\n",
      "28627\n"
     ]
    }
   ],
   "source": [
    "print len(train_set_x)\n",
    "print len(train_set_y)\n",
    "print len(test_set_x)\n",
    "print len(test_set_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n"
     ]
    }
   ],
   "source": [
    "batchsize = 1000\n",
    "n_epoch = 3\n",
    "\n",
    "model = LeNet()\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "if gpu_flag >= 0:\n",
    "    cuda.get_device(gpu_flag).use()\n",
    "    model.to_gpu()\n",
    "    \n",
    "# ---Train---\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    print \"epoch: %d\" % epoch\n",
    "\n",
    "    perm = np.random.permutation(N)\n",
    "    for i in range(0, N, batchsize):\n",
    "        x_batch = xp.asarray(x_train[perm[i:i + batchsize]],dtype=np.float32)\n",
    "        y_batch = xp.asarray(y_train[perm[i:i + batchsize]],dtype=np.int32)\n",
    "        \n",
    "        model.zerograds()\n",
    "        loss,train_acc = model.forward_Train(x_batch, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---probability---\n",
      "Liver : 0.135699\n",
      "Cyst  : 0.000000\n",
      "FNH   : 0.170494\n",
      "CCC   : 0.040710\n",
      "HCC   : 0.012526\n",
      "Meta  : 0.640571\n"
     ]
    }
   ],
   "source": [
    "#---Test(simple 6 classes clasificate)---\n",
    "\n",
    "start_time = time.clock()\n",
    "min_result = 1.000\n",
    "acc_label2 = []\n",
    "max_acc=0.0\n",
    "\n",
    "    \n",
    "sum_accuracy = 0   \n",
    "for i in range(0, N_test, batchsize):\n",
    "    x_batch = xp.asarray(x_test[i:i + batchsize])\n",
    "    y_batch = xp.asarray(y_test[i:i + batchsize])\n",
    "    acc = model.forward_Test(x_batch, y_batch)\n",
    "    sum_accuracy += float(acc.data) * len(y_batch)     \n",
    "test_result = sum_accuracy / N_test\n",
    "\n",
    "min_label = []\n",
    "acc_label = np.empty((0,6),int)\n",
    "for i in range(0, N_test, batchsize):\n",
    "    x_batch = xp.asarray(x_test[i:i + batchsize])\n",
    "    y_batch = xp.asarray(y_test[i:i + batchsize])\n",
    "    acc = np.array([model.forward_label(x_batch,y_batch)])\n",
    "    acc_label = np.append(acc_label, np.array([acc[0]]), axis=0)\n",
    "acc_label2 = sum(acc_label)/N_test\n",
    "\n",
    "print(\"---probability---\")\n",
    "print \"Liver : %f\" %(acc_label2[0])\n",
    "print \"Cyst  : %f\" %(acc_label2[1])\n",
    "print \"FNH   : %f\" %(acc_label2[2])\n",
    "print \"CCC   : %f\" %(acc_label2[3])\n",
    "print \"HCC   : %f\" %(acc_label2[4])\n",
    "print \"Meta  : %f\" %(acc_label2[5])\n",
    "    \n",
    "end_time = time.clock()\n",
    "#print end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
